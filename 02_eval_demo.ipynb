{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Evaluate your Model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rungpu is simple to use for Evaluations and Inference as well. You can finetune your model in a few lines of code.  \n",
    "A few basics: \n",
    "\n",
    "1. Pick your dataset of your choice. \n",
    "2. Pick any Model you Finetuned - use the `train_id` you got when you finished fine-tuning\n",
    "\n",
    "We have sample code to help you get started, with popular models, including Mistral v0.2, Llama 3, Gemma, etc.\n",
    "\n",
    "Let's start with importing the libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the `train_id` you got after finetuning your model to run Evaluations on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = '<train_id>' #The unique id for your finetuned model which is the train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Unique RunGPU Client ID and Secret here. \n",
    "client_id = '<Your RunGPU Client ID>'\n",
    "client_secret = '<Your RunGPU Client Secret>'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Client class to get access to RunGPU services. \n",
    "from rungpu import Client\n",
    "client = Client(client_id=client_id, client_secret=client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Evaluation? \n",
    "\n",
    "Once you train your model, you would want to test it and ask questions to make sure the model is usable. You can do so by using RunGPU to run Batch Inference jobs on your trained model to check how it responds to your prompts. \n",
    "\n",
    "You'll need 2 pieces of information in this case to start running eval/inference jobs on your model\n",
    "- `model_id` - The model_id of the RunGPU trained model also known as `train_id`\n",
    "- `dataset_id` - The Eval Dataset that's essentially a list of prompts you would want to have to pass into the model to generate responses. You will create this using the `Dataset.create_dataset()` function as below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your Eval Dataset\n",
    "\n",
    "- You can create your Eval dataset in jsonl format in `{'prompt': '<question string>' , 'completion': '<output text>'}` format. Name the file data.jsonl\n",
    "\n",
    "- A dataset can be imported as a txt file with json objects in it. \n",
    "```\n",
    "gdrive_url= '<link to shareable gdrive link>'\n",
    "```\n",
    "- Use the `Dataset()` object with arguments\n",
    "```\n",
    "`mode='eval'` \n",
    "`config={'config':{'type':'google_drive','src_file':gdrive_url}}`\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rungpu import Dataset\n",
    "\n",
    "gdrive_url= \"<Shareable Google Drive Link>\"\n",
    "\n",
    "eval_config={'config':{'type':'google_drive','src_file':gdrive_url}}\n",
    "\n",
    "eval_dataset = Dataset(client=client, mode='eval',config = eval_config)\n",
    "\n",
    "eval_dataset = eval_dataset.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rungpu_dse_<uuid>\n"
     ]
    }
   ],
   "source": [
    "eval_dataset\n",
    "eval_dataset_id = eval_dataset['dataset_id']\n",
    "print(\"rungpu_dse_<uuid>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rungpu import Eval\n",
    "# Enter the model_id, dataset_id and client object into an Eval Object. \n",
    "eval = Eval( client=client, model_id= model_id, dataset_id=eval_dataset_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration : \n",
      "{'model_id': 'google-gemma-2-9b-it-8-bit-54688c04-508a-11ef-8438-b8ca3a5c98fc-rungpu_dst_8c5ccb7e-aa01-4e1b-9d35-1253bdbc4249', 'dataset_id': 'rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3', 'client_id': 'n6p7iWSrknJqkLIwX0PGi', 'client_secret': '3b32447eab2155d1905c44dcf0506e5ceddf3827b'}\n"
     ]
    }
   ],
   "source": [
    "response = eval.run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Streaming to eval dataset_id file rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3/output.jsonl'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Check the Status of your Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rungpu import EvalStatus\n",
    "eval_status = EvalStatus(client=client,model_id=model_id, dataset_id=eval_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_elapsed': 'None',\n",
       " 'train_status': {'command': 'EVAL',\n",
       "  'status': 'IN QUEUE',\n",
       "  'eval_id': 'google-gemma-2-9b-it-8-bit-54688c04-508a-11ef-8438-b8ca3a5c98fc-rungpu_dst_8c5ccb7e-aa01-4e1b-9d35-1253bdbc4249-rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3',\n",
       "  'client_id': 'n6p7iWSrknJqkLIwX0PGi',\n",
       "  'model_id': 'google-gemma-2-9b-it-8-bit-54688c04-508a-11ef-8438-b8ca3a5c98fc-rungpu_dst_8c5ccb7e-aa01-4e1b-9d35-1253bdbc4249',\n",
       "  'dataset_id': 'rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3',\n",
       "  'eval_start': None,\n",
       "  'eval_end': None}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_status.get_eval_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check the responses \n",
    "\n",
    "This function streams responses as the file is populated. \n",
    "\n",
    "\n",
    "> Feel free to Kill this function whenever as it might keep running if the file isn't populated yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_status.eval_progress()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
