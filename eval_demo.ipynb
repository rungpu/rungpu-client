{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Evaluate your Model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rungpu is simple to use for Evaluations and Inference as well. You can finetune your model in a few lines of code.  \n",
    "A few basics: \n",
    "\n",
    "1. Pick your dataset of your choice. \n",
    "2. Pick any Model from Huggingface. \n",
    "3. Build your own finetuning configuration. Or choose from one of our templates!\n",
    "\n",
    "We have sample code to help you get started, with popular models, including Mistral v0.2, Llama 3, Gemma, etc.\n",
    "\n",
    "Let's start with importing the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config Cell needs to be deleted in Prod. \n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('system.ini')\n",
    "\n",
    "client_id = config['rungpu_client']['client_id']\n",
    "client_secret = config['rungpu_client']['client_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Enter your Unique RunGPU Client ID and Secret here. \n",
    "# client_id = '<Your RunGPU Client ID>'\n",
    "# client_secret = '<Your RunGPU Client Secret>'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Client class to get access to RunGPU services. \n",
    "from rungpu import Client\n",
    "client = Client(client_id=client_id, client_secret=client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Evaluation? \n",
    "\n",
    "Once you train your model, you would want to test it and ask questions to make sure the model is usable. You can do so by using RunGPU to run Batch Inference jobs on your trained model to check how it responds to your prompts. \n",
    "\n",
    "You'll need 2 pieces of information in this case to start running eval/inference jobs on your model\n",
    "- `model_id` - The model_id of the RunGPU trained model \n",
    "- `dataset_id` - The Eval Dataset that's essentially a list of prompts you would want to have to pass into the model to generate responses. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b9f534c2-4e1f-11ef-8cf2-b8ca3a5c98fc-rungpu_dst_afc3a184-e8e7-4c1d-802f-ba5c9009d50e'\n",
    "dataset_id = 'rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rungpu import Eval\n",
    "# Enter the model_id, dataset_id and client object into an Eval Object. \n",
    "eval = Eval( client=client, model_id= model_id, dataset_id=dataset_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b9f534c2-4e1f-11ef-8cf2-b8ca3a5c98fc-rungpu_dst_afc3a184-e8e7-4c1d-802f-ba5c9009d50e', 'dataset_id': 'rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3', 'client_id': 'n6p7iWSrknJqkLIwX0PGi', 'client_secret': '3b32447eab2155d1905c44dcf0506e5ceddf3827b'}\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = eval.run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Streaming to eval dataset_id file rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3/output.jsonl'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curl -X POST https://p2y2xn5ac6.execute-api.us-east-1.amazonaws.com/eval \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d '{\"model_id\": \"mistralai-Mistral-7B-Instruct-v0.2-8-bit-b9f534c2-4e1f-11ef-8cf2-b8ca3a5c98fc-rungpu_dst_afc3a184-e8e7-4c1d-802f-ba5c9009d50e\", \"dataset_id\": \"rungpu_dse_2fc127b9-33e2-46a8-97f4-727e84cf7b88\", \"client_id\": \"n6p7iWSrknJqkLIwX0PGi\", \"client_secret\": \"3b32447eab2155d1905c44dcf0506e5ceddf3827b\"}' \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Check the Status of your Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rungpu import EvalStatus\n",
    "eval_status = EvalStatus(client=client,model_id=model_id, dataset_id=dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'time_elapsed': '2.437857683333333', 'train_status': {'command': 'EVAL', 'status': 'FINISHED', 'eval_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b9f534c2-4e1f-11ef-8cf2-b8ca3a5c98fc-rungpu_dst_afc3a184-e8e7-4c1d-802f-ba5c9009d50e-rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3', 'client_id': 'n6p7iWSrknJqkLIwX0PGi', 'model_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b9f534c2-4e1f-11ef-8cf2-b8ca3a5c98fc-rungpu_dst_afc3a184-e8e7-4c1d-802f-ba5c9009d50e', 'dataset_id': 'rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3', 'eval_start': '2024-07-31 11:38:10.224141', 'eval_end': '2024-07-31 11:40:36.495602'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time_elapsed': '2.437857683333333',\n",
       " 'train_status': {'command': 'EVAL',\n",
       "  'status': 'FINISHED',\n",
       "  'eval_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b9f534c2-4e1f-11ef-8cf2-b8ca3a5c98fc-rungpu_dst_afc3a184-e8e7-4c1d-802f-ba5c9009d50e-rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3',\n",
       "  'client_id': 'n6p7iWSrknJqkLIwX0PGi',\n",
       "  'model_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b9f534c2-4e1f-11ef-8cf2-b8ca3a5c98fc-rungpu_dst_afc3a184-e8e7-4c1d-802f-ba5c9009d50e',\n",
       "  'dataset_id': 'rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3',\n",
       "  'eval_start': '2024-07-31 11:38:10.224141',\n",
       "  'eval_end': '2024-07-31 11:40:36.495602'}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_status.get_eval_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
