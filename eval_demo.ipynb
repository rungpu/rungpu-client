{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Evaluate your Model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rungpu is simple to use for Evaluations and Inference as well. You can finetune your model in a few lines of code.  \n",
    "A few basics: \n",
    "\n",
    "1. Pick your dataset of your choice. \n",
    "2. Pick any Model from Huggingface. \n",
    "3. Build your own finetuning configuration. Or choose from one of our templates!\n",
    "\n",
    "We have sample code to help you get started, with popular models, including Mistral v0.2, Llama 3, Gemma, etc.\n",
    "\n",
    "Let's start with importing the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Unique RunGPU Client ID and Secret here. \n",
    "client_id = '<Your RunGPU Client ID>'\n",
    "client_secret = '<Your RunGPU Client Secret>'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Client class to get access to RunGPU services. \n",
    "from rungpu import Client\n",
    "client = Client(client_id=client_id, client_secret=client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Evaluation? \n",
    "\n",
    "Once you train your model, you would want to test it and ask questions to make sure the model is usable. You can do so by using RunGPU to run Batch Inference jobs on your trained model to check how it responds to your prompts. \n",
    "\n",
    "You'll need 2 pieces of information in this case to start running eval/inference jobs on your model\n",
    "- `model_id` - The model_id of the RunGPU trained model \n",
    "- `dataset_id` - The Eval Dataset that's essentially a list of prompts you would want to have to pass into the model to generate responses. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your Eval Dataset\n",
    "\n",
    "- You can create your Eval dataset in jsonl format in `{'prompt': '<question string>' , 'completion': '<output text>'}` format. Name the file data.jsonl\n",
    "\n",
    "- A dataset can be imported as a txt file with json objects in it. \n",
    "```\n",
    "gdrive_url= '<link to shareable gdrive link>'\n",
    "```\n",
    "- Use the `Dataset()` object with arguments\n",
    "```\n",
    "`mode='eval'` \n",
    "`config={'config':{'type':'google_drive','src_file':gdrive_url}}`\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rungpu import Dataset\n",
    "\n",
    "gdrive_url= \"<Shareable Google Drive Link>\"\n",
    "\n",
    "eval_config={'config':{'type':'google_drive','src_file':gdrive_url}}\n",
    "\n",
    "eval_dataset = Dataset(client=client, mode='eval',config = eval_config)\n",
    "\n",
    "eval_dataset = eval_dataset.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset\n",
    "eval_dataset_id = eval_dataset['dataset_id']\n",
    "print(eval_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = '<model_id>' #The unique id for your finetuned model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rungpu import Eval\n",
    "# Enter the model_id, dataset_id and client object into an Eval Object. \n",
    "eval = Eval( client=client, model_id= model_id, dataset_id=eval_dataset_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration : \n",
      "{'model_id': 'google-gemma-2-9b-it-8-bit-54688c04-508a-11ef-8438-b8ca3a5c98fc-rungpu_dst_8c5ccb7e-aa01-4e1b-9d35-1253bdbc4249', 'dataset_id': 'rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3', 'client_id': 'n6p7iWSrknJqkLIwX0PGi', 'client_secret': '3b32447eab2155d1905c44dcf0506e5ceddf3827b'}\n"
     ]
    }
   ],
   "source": [
    "response = eval.run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Streaming to eval dataset_id file rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3/output.jsonl'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Check the Status of your Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rungpu import EvalStatus\n",
    "eval_status = EvalStatus(client=client,model_id=model_id, dataset_id=dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_elapsed': 'None',\n",
       " 'train_status': {'command': 'EVAL',\n",
       "  'status': 'IN QUEUE',\n",
       "  'eval_id': 'google-gemma-2-9b-it-8-bit-54688c04-508a-11ef-8438-b8ca3a5c98fc-rungpu_dst_8c5ccb7e-aa01-4e1b-9d35-1253bdbc4249-rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3',\n",
       "  'client_id': 'n6p7iWSrknJqkLIwX0PGi',\n",
       "  'model_id': 'google-gemma-2-9b-it-8-bit-54688c04-508a-11ef-8438-b8ca3a5c98fc-rungpu_dst_8c5ccb7e-aa01-4e1b-9d35-1253bdbc4249',\n",
       "  'dataset_id': 'rungpu_dse_4ccd5571-81b6-4bd2-9de9-115aa5e03fc3',\n",
       "  'eval_start': None,\n",
       "  'eval_end': None}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "eval_status.get_eval_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
