{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started with RunGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rungpu is simple to use. You can finetune your model in a few lines of code.  \n",
    "A few basics: \n",
    "\n",
    "1. Pick your dataset of your choice. \n",
    "2. Pick any Model from Huggingface. \n",
    "3. Build your own finetuning configuration. Or choose from one of our templates!\n",
    "\n",
    "We have sample code to help you get started, with popular models, including Mistral v0.2, Llama 3, Gemma, etc.\n",
    "\n",
    "Let's start with importing the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:33.903714Z",
     "iopub.status.busy": "2024-05-23T03:53:33.903037Z",
     "iopub.status.idle": "2024-05-23T03:53:33.957839Z",
     "shell.execute_reply": "2024-05-23T03:53:33.957526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets import the model first\n",
    "from rungpu import Finetune\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Client object for Authentication. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Client class to get access to RunGPU services. \n",
    "from rungpu import Client\n",
    "# Enter your Unique RunGPU Client ID and Secret here. \n",
    "client_id = '<Your RunGPU Client ID>'\n",
    "client_secret = '<Your RunGPU Client Secret>'\n",
    "\n",
    "client = Client(client_id, client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started with creating your dataset. \n",
    "\n",
    "### Why? \n",
    "\n",
    "In this example, we will use a dataset to train the Chatbot Model to make sure it learns specific information about our use case. \n",
    "\n",
    "\n",
    "But lets start with a simpler question:\n",
    "\n",
    "#### What is a dataset and why do you need it? \n",
    "\n",
    "A dataset is simply a document or simply a corpus of text that holds the knowledge you would want to train your chatbot on. \n",
    "It could be anything under the sun, general or specific. Since most foundational models are trained on a lot of general knowledge, \n",
    "it would most likely be something specific. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical dataset config would look like the following\n",
    "For example, for a file in aws S3, \n",
    "```\n",
    "{\n",
    "    \"config\": {\n",
    "        \"type\": \"s3\",\n",
    "        \"provider\": \"AWS\",\n",
    "        \"env_auth\": \"false\",\n",
    "        \"access_key_id\": <access_key_id for aws>,\n",
    "        \"secret_access_key\": <secret access key>,\n",
    "        \"region\": <aws region>,\n",
    "        \"src_file\": \"/rungpu-dev/test.txt\",\n",
    "        \"dest_file\": \"data.txt\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "the `config` property is where you'll be entering all your config information for where your file will be coming from. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = config['aws']['AWS_ACCESS_KEY_ID']\n",
    "aws_secret_access_key = config['aws']['AWS_SECRET_ACCESS_KEY']\n",
    "aws_region=config['aws']['AWS_REGION']\n",
    "\n",
    "\n",
    "dataset_config = {\n",
    "    \"config\": {\n",
    "        \"type\": \"s3\",\n",
    "        \"provider\": \"AWS\",\n",
    "        \"env_auth\": \"false\",\n",
    "        \"access_key_id\": aws_access_key_id,\n",
    "        \"secret_access_key\": aws_secret_access_key,\n",
    "        \"region\": aws_region,\n",
    "        \"src_file\": \"/rungpu-dev/test.txt\",\n",
    "\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:33.959895Z",
     "iopub.status.busy": "2024-05-23T03:53:33.959767Z",
     "iopub.status.idle": "2024-05-23T03:53:45.266074Z",
     "shell.execute_reply": "2024-05-23T03:53:45.265306Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from rungpu import Dataset\n",
    "\n",
    "config_path = \"./dataset.json\"\n",
    "gdrive_url= \"https://drive.google.com/file/d/1zj8v7Nxf2gZuScLs8hzcu-jSBYkOP-no/view?usp=sharing\"\n",
    "# Change to json objects , not files. \n",
    "gdrive_config = {'config':{'type':'google_drive','src_file':gdrive_url}}\n",
    "\n",
    "\n",
    "dataset = Dataset(client=client,mode='train', config=gdrive_config)\n",
    "\n",
    "# Pulling the Dataset from the cloud. \n",
    "dataset_response = dataset.create_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'command': 'Create Dataset',\n",
       " 'created_at': '2024-07-24 14:53:48.179637',\n",
       " 'dataset_id': 'rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c',\n",
       " 'src_file': 'https://drive.google.com/file/d/1zj8v7Nxf2gZuScLs8hzcu-jSBYkOP-no/view?usp=sharing',\n",
       " 'data_source': 'google_drive'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Dataset ID.\n",
    "\n",
    "Running the code cell above returns you a response which contains the details of the dataset you just created. \n",
    "\n",
    "The dataset you created is stored securely on our servers for the purposes of finetuning the model (it can be removed later.)\n",
    "\n",
    "This response object you get on running the `create_dataset()` function contains the dataset_id unique to the dataset you just created. The dataset id looks something like the following: \n",
    "\n",
    "`rungpu_dataset_<random_unique_id>`\n",
    "\n",
    "You can plug this id into your finetuning config as below for the `dataset_id` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = dataset_response['dataset_id']\n",
    "dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Create your model and start Finetuning!\n",
    "\n",
    "Your finetuning job flow includes the creation of the model. So the finetuning config would include the config for your model. \n",
    "\n",
    "The finetuning config looks something like this: \n",
    "\n",
    "```\n",
    "    {\n",
    "    \"base_model\": <huggingface base model>,\n",
    "    \"quant\": 8,\n",
    "    \"num_steps\": 100,\n",
    "    \"dataset_id\": <rungpu dataset id will be added by the Finetune Object when you declare it.>,\n",
    "    \"strategy\": \"lora\",\n",
    "    \"checkpoint_steps\": 10,\n",
    "    \"training_size\": 1000,\n",
    "    \"peft_config\": {\n",
    "        \"lora\": {\n",
    "            \"r\": 16,\n",
    "            \"alpha\": 16,\n",
    "            \"target_modules\": [\n",
    "                \"q_proj\",\n",
    "                \"k_proj\",\n",
    "                \"v_proj\",\n",
    "                \"o_proj\",\n",
    "                \"gate_proj\",\n",
    "                \"up_proj\",\n",
    "                \"down_proj\",\n",
    "                \"lm_head\"\n",
    "            ],\n",
    "            \"bias\": \"none\",\n",
    "            \"lora_dropout\": 0.05\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's your finetuning config. \n",
    "ft_config = {\n",
    "    \"base_model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    \"quant\": 8,\n",
    "    \"num_steps\": 10,\n",
    "    \"strategy\": \"lora\",\n",
    "    \"checkpoint_steps\": 1,\n",
    "    \"training_size\": 1000,\n",
    "    \"model_max_length\": 4096,\n",
    "    \"prompt_max_length\": 512,\n",
    "    \"gguf_flag\": True,\n",
    "    \"peft_config\": {\n",
    "        \"lora\": {\n",
    "            \"r\": 16,\n",
    "            \"alpha\": 16,\n",
    "            \"target_modules\": [\n",
    "                \"q_proj\",\n",
    "                \"k_proj\",\n",
    "                \"v_proj\",\n",
    "                \"o_proj\",\n",
    "                \"gate_proj\",\n",
    "                \"up_proj\",\n",
    "                \"down_proj\",\n",
    "                \"lm_head\"\n",
    "            ],\n",
    "            \"bias\": \"none\",\n",
    "            \"lora_dropout\": 0.05\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:45.299402Z",
     "iopub.status.busy": "2024-05-23T03:53:45.299080Z",
     "iopub.status.idle": "2024-05-23T03:53:48.509993Z",
     "shell.execute_reply": "2024-05-23T03:53:48.509167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'command': 'Finetune',\n",
       " 'status': 'IN_QUEUE',\n",
       " 'train_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c',\n",
       " 'base_model': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       " 'quantization': 8,\n",
       " 'dataset_id': 'rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c',\n",
       " 'peft_strategy': 'lora',\n",
       " 'checkpoints': 1,\n",
       " 'num_steps': 10,\n",
       " 'training_size': 1000,\n",
       " 'peft_config': {'lora': {'r': 16,\n",
       "   'alpha': 16,\n",
       "   'target_modules': ['q_proj',\n",
       "    'k_proj',\n",
       "    'v_proj',\n",
       "    'o_proj',\n",
       "    'gate_proj',\n",
       "    'up_proj',\n",
       "    'down_proj',\n",
       "    'lm_head'],\n",
       "   'bias': 'none',\n",
       "   'lora_dropout': 0.05}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the finetuning config\n",
    "import json\n",
    "\n",
    "# Getting the config file\n",
    "config_path = './ft_config.json'\n",
    "\n",
    "# Remove files. Just json objects. \n",
    "\n",
    "# Creating the Finetune object, and plugging in the config we created, finetuning specific. \n",
    "finetune = Finetune(client,dataset_id=dataset_id,config=ft_config)\n",
    "\n",
    "#Calling the run_finetune() function to kick off the finetuning job. \n",
    "response = finetune.run_finetune()\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Finetune `run_id`\n",
    "\n",
    "Once you execute the `run_finetune()` function on the finetune object, you essentially kick off a finetuning object on the backend. \n",
    "the `run_finetune()` call returns a response object from the server, that contains a `run_id`, which is the unique identifier for this specific finetuning job run. \n",
    "\n",
    "You can use this run_id to retrieve the details on how the run job progressed, and other information about model configurations and finetuning strategies. This is put in place with several other functions we provide to check the finetune job details. \n",
    "\n",
    "\n",
    "The response of the `run_finetune()` command looks something like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:48.515180Z",
     "iopub.status.busy": "2024-05-23T03:53:48.514635Z",
     "iopub.status.idle": "2024-05-23T03:53:48.524482Z",
     "shell.execute_reply": "2024-05-23T03:53:48.524019Z"
    }
   },
   "outputs": [],
   "source": [
    "response\n",
    "train_id = response['train_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see what our training id looks like\n",
    "\n",
    "The training id is a combination of the model_id and the training dataset id that it was trained on. This gives your training job/ finetuned model a unique identity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the status of your run. \n",
    "\n",
    "Use the finetune object to call the `get_status` function, which will help us get run status of current or past finetuning run jobs based on their `run_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:48.532938Z",
     "iopub.status.busy": "2024-05-23T03:53:48.532760Z",
     "iopub.status.idle": "2024-05-23T03:53:51.439590Z",
     "shell.execute_reply": "2024-05-23T03:53:51.438552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train_Id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c', 'time_elapsed': 'null', 'train_status': {'command': 'Finetune', 'train_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c', 'status': 'IN QUEUE', 'phase': 'TRAINING', 'client_id': 'n6p7iWSrknJqkLIwX0PGi', 'model_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc', 'base_model': 'mistralai/Mistral-7B-Instruct-v0.2', 'dataset_id': 'rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c', 'run_start': 'null', 'run_end': 'null', 'export_start': 'null', 'export_end': 'null', 'error': 'Job Still in Queue', 'quantization': 8, 'strategy': 'lora', 'checkpoint_steps': 1, 'training_steps': 10, 'training_split': 1000, 'peft_config': {'lora': {'r': 16, 'alpha': 16, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'lm_head'], 'bias': 'none', 'lora_dropout': 0.05}}, 'run_history': 'null'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Train_Id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c',\n",
       " 'time_elapsed': 'null',\n",
       " 'train_status': {'command': 'Finetune',\n",
       "  'train_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c',\n",
       "  'status': 'IN QUEUE',\n",
       "  'phase': 'TRAINING',\n",
       "  'client_id': 'n6p7iWSrknJqkLIwX0PGi',\n",
       "  'model_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc',\n",
       "  'base_model': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       "  'dataset_id': 'rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c',\n",
       "  'run_start': 'null',\n",
       "  'run_end': 'null',\n",
       "  'export_start': 'null',\n",
       "  'export_end': 'null',\n",
       "  'error': 'Job Still in Queue',\n",
       "  'quantization': 8,\n",
       "  'strategy': 'lora',\n",
       "  'checkpoint_steps': 1,\n",
       "  'training_steps': 10,\n",
       "  'training_split': 1000,\n",
       "  'peft_config': {'lora': {'r': 16,\n",
       "    'alpha': 16,\n",
       "    'target_modules': ['q_proj',\n",
       "     'k_proj',\n",
       "     'v_proj',\n",
       "     'o_proj',\n",
       "     'gate_proj',\n",
       "     'up_proj',\n",
       "     'down_proj',\n",
       "     'lm_head'],\n",
       "    'bias': 'none',\n",
       "    'lora_dropout': 0.05}},\n",
       "  'run_history': 'null'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rungpu import TrainStatus, Client\n",
    "client = Client(client_id=client_id, client_secret=client_secret)\n",
    "train_status = TrainStatus(client,train_id)\n",
    "status = train_status.get_status()\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train_Id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c', 'time_elapsed': 'null', 'train_status': {'command': 'Finetune', 'train_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c', 'status': 'IN QUEUE', 'phase': 'TRAINING', 'client_id': 'n6p7iWSrknJqkLIwX0PGi', 'model_id': 'mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc', 'base_model': 'mistralai/Mistral-7B-Instruct-v0.2', 'dataset_id': 'rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c', 'run_start': 'null', 'run_end': 'null', 'export_start': 'null', 'export_end': 'null', 'error': 'Job Still in Queue', 'quantization': 8, 'strategy': 'lora', 'checkpoint_steps': 1, 'training_steps': 10, 'training_split': 1000, 'peft_config': {'lora': {'r': 16, 'alpha': 16, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'lm_head'], 'bias': 'none', 'lora_dropout': 0.05}}, 'run_history': 'null'}}\n",
      "can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 1,738\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 10\n",
      "  Number of trainable parameters = 42,520,592\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-1\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-2\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-3\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-4\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-5\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-6\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-7\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-8\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-9\n",
      "Saving model checkpoint to /home/rungpu/models//mistralai-Mistral-7B-Instruct-v0.2/8-bit/mistralai-Mistral-7B-Instruct-v0.2-8-bit-b78fc644-4978-11ef-8748-b8ca3a5c98fc-rungpu_dst_7882f5b6-fce1-416d-8bf2-289303761a9c/checkpoint-10\n",
      "Training Completed.\n"
     ]
    }
   ],
   "source": [
    "train_status.progress()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
