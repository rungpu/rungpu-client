{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started with RunGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunGPU is a serverless platform which gives you immediate access to GPU's on the cloud.\n",
    "\n",
    "Rungpu is simple to use, you don't have to set up any machines or configure any pods,containers.\n",
    "You can instantly start finetuning your model with a few lines of code. \n",
    "\n",
    "A few basics: \n",
    "\n",
    "1. Pick a dataset of your choice. \n",
    "2. Pick any model from Huggingface. \n",
    "3. Build your own finetuning configuration or choose from one of our templates!\n",
    "\n",
    "We have sample code to help you get started, with popular models, including Mistral, Llama 3, Gemma, etc.\n",
    "\n",
    "You can request your client Id and Client Secret by sending an email to contact@rungpu.ai\n",
    "\n",
    "Let's start with importing the libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Client object for Authentication. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"<Your RunGPU client ID>\"\n",
    "client_secret = \"<Your RunGPU client Secret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rungpu import Client\n",
    "\n",
    "client = Client(client_id, client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started with creating your dataset. \n",
    "\n",
    "In this example, we will use a dataset to train the Chatbot Model to make sure it learns specific information about our use case. \n",
    "\n",
    "\n",
    "But lets start with a simpler question:\n",
    "\n",
    "#### What is a dataset and why do you need it? \n",
    "\n",
    "A dataset is a document or a corpus of text that holds the knowledge you would want to train your chatbot for a specific use-case.\n",
    "\n",
    "Here's what a sample dataset in jsonl format looks like: \n",
    "\n",
    "```[\n",
    "    {\"prompt\": \"What is the capital of France?\", \"response\": \"Paris\"},\n",
    "    {\"prompt\": \"Who wrote 'To Kill a Mockingbird'?\", \"response\": \"Harper Lee\"},\n",
    "    {\"prompt\": \"What is the boiling point of water?\", \"response\": \"100°C or 212°F\"},\n",
    "    {\"prompt\": \"Who painted the Mona Lisa?\", \"response\": \"Leonardo da Vinci\"},\n",
    "    {\"prompt\": \"What is the largest planet in our solar system?\", \"response\": \"Jupiter\"},\n",
    "    {\"prompt\": \"What year did the Titanic sink?\", \"response\": \"1912\"},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now create a dataset configuration. \n",
    "The config below shows an example to load the dataset file from an S3 bucket:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"config\": {\n",
    "        \"type\": \"s3\",\n",
    "        \"provider\": \"AWS\",\n",
    "        \"env_auth\": \"false\",\n",
    "        \"access_key_id\": \"<aws_access_key_id>\",\n",
    "        \"secret_access_key\": \"<aws_secret_access_key>\",\n",
    "        \"region\": \"<aws_region>\",\n",
    "        \"src_file\": \"/<bucket_name>/test.jsonl\",\n",
    "\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Drive Option\n",
    "If you don't have access to a cloud provider for storage and have your dataset stored locally, \n",
    "you can get started by simply having your file in your google drive\n",
    "and having a shareable link pointing to that file. The config for that looks like this: \n",
    "\n",
    "```\n",
    "config = {'config':\n",
    "            {'type':'google_drive',\n",
    "             'src_file':<shareable_gdrive_link>\n",
    "             }\n",
    "         }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'config':\n",
    "            {'type':'google_drive',\n",
    "             'src_file':'<shareable_gdrive_link>'\n",
    "             }\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:33.959895Z",
     "iopub.status.busy": "2024-05-23T03:53:33.959767Z",
     "iopub.status.idle": "2024-05-23T03:53:45.266074Z",
     "shell.execute_reply": "2024-05-23T03:53:45.265306Z"
    }
   },
   "outputs": [],
   "source": [
    "from rungpu import Dataset\n",
    "\n",
    "dataset = Dataset(client=client, config=config)\n",
    "\n",
    "# Create the Dataset for finetuning. \n",
    "dataset_response = dataset.create_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Dataset ID.\n",
    "\n",
    "Running the code cell above returns you a response which contains the details of the dataset you just created. \n",
    "\n",
    "The dataset you created is stored securely on our servers for the purposes of finetuning the model (it can be removed later.)\n",
    "\n",
    "This response object you get on running the `create_dataset()` function contains the dataset_id unique to the dataset you just created. The dataset id looks something like the following: \n",
    "\n",
    "`rungpu_dataset_<random_unique_id>`\n",
    "\n",
    "You can plug this id into your finetuning config as below for the `dataset_id` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = dataset_response['dataset_id']\n",
    "dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Create your model and start Finetuning!\n",
    "\n",
    "Here are some examples of models Huggingface provides that you can try out: \n",
    "\n",
    "- Llama-3-8b\n",
    "- Llama-3-8b-instruct\n",
    "- Mistral-7b-instruct-v0.1\n",
    "- Mistral-7b-instruct-v0.2\n",
    "- Mistral-7b\n",
    "- Gemma-2b\n",
    "- Gemma-2B-Instruct\n",
    "- Gemma-7b\n",
    "- Gemma-7B-Instruct\n",
    "- distilbert-distilgpt2\n",
    "- Mistral-7b-instruct-v0.3\n",
    "- Code-llama-13b-instruct\n",
    "- Llama-2-7b\n",
    "- Llama-2-7b-chat\n",
    "- Llama-2-13b\n",
    "- Llama-2-13b-chat\n",
    "- Mixtral-8x7B-Instruct-v0.1\n",
    "- Phi-2\n",
    "- Zephyr-7b-beta\n",
    "\n",
    "\n",
    "We will now train a distilbert quantized to 8-bit.\n",
    "\n",
    "Note: You will require the Huggingface path of the model.\n",
    "\n",
    "An example of a finetuning configuration is given below: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's your finetuning config. \n",
    "ft_config = {\n",
    "    \"base_model\": \"distilbert/distilgpt2\",\n",
    "    \"quant\": 8,\n",
    "    \"num_steps\": 1000,\n",
    "    \"strategy\": \"lora\",\n",
    "    \"checkpoint_steps\": 100,\n",
    "    \"training_size\": 1000,\n",
    "    \"peft_config\": {\n",
    "        \"lora\": {\n",
    "            \"r\": 16,\n",
    "            \"alpha\": 16,\n",
    "            \"target_modules\": [\n",
    "                \"q_proj\",\n",
    "                \"k_proj\",\n",
    "                \"v_proj\",\n",
    "                \"o_proj\",\n",
    "                \"gate_proj\",\n",
    "                \"up_proj\",\n",
    "                \"down_proj\",\n",
    "                \"lm_head\"\n",
    "            ],\n",
    "            \"bias\": \"none\",\n",
    "            \"lora_dropout\": 0.05\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:45.299402Z",
     "iopub.status.busy": "2024-05-23T03:53:45.299080Z",
     "iopub.status.idle": "2024-05-23T03:53:48.509993Z",
     "shell.execute_reply": "2024-05-23T03:53:48.509167Z"
    }
   },
   "outputs": [],
   "source": [
    "from rungpu import Finetune\n",
    "\n",
    "# Creating the Finetune object, using the dataset and finetuning configuration we just created. \n",
    "finetune = Finetune(client,dataset_id=dataset_id,config=ft_config)\n",
    "\n",
    "#Calling the run_finetune() function to kick off the finetuning job. \n",
    "response = finetune.run_finetune()\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Finetune `run_id`\n",
    "\n",
    "The `run_finetune()` function starts the model training. The response object contains a `run_id` which is the unique identifier for this specific finetuning job run.\n",
    "\n",
    "You can use `run_id` to track the progress of the training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:48.515180Z",
     "iopub.status.busy": "2024-05-23T03:53:48.514635Z",
     "iopub.status.idle": "2024-05-23T03:53:48.524482Z",
     "shell.execute_reply": "2024-05-23T03:53:48.524019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = response['run_id']\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the status of your run. \n",
    "\n",
    "Use the finetune object to call the `get_status` function, which will help us get the status of training using the `run_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:48.532938Z",
     "iopub.status.busy": "2024-05-23T03:53:48.532760Z",
     "iopub.status.idle": "2024-05-23T03:53:51.439590Z",
     "shell.execute_reply": "2024-05-23T03:53:51.438552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RunID': 'distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c',\n",
       " 'time_elapsed': '2024-06-07 12:36:45.661287',\n",
       " 'RunStatus': {'command': 'Finetune',\n",
       "  'status': 'COMPLETED',\n",
       "  'phase': 'MODEL_TRAINED',\n",
       "  'client_id': 'arun_prasad',\n",
       "  'model_id': 'distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc',\n",
       "  'base_model': 'distilbert/distilgpt2',\n",
       "  'dataset_id': 'rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c',\n",
       "  'run_start': '2024-06-07 12:27:28.235440',\n",
       "  'run_end': '2024-06-07 12:36:45.661287',\n",
       "  'export_start': '2024-06-07 12:28:21.299823',\n",
       "  'export_end': '2024-06-07 12:36:45.645127',\n",
       "  'quantization': 8,\n",
       "  'strategy': 'lora',\n",
       "  'checkpoint_steps': 10,\n",
       "  'training_steps': 100,\n",
       "  'training_split': 1000,\n",
       "  'peft_config': {'lora': {'r': 16,\n",
       "    'alpha': 16,\n",
       "    'target_modules': ['q_proj',\n",
       "     'k_proj',\n",
       "     'v_proj',\n",
       "     'o_proj',\n",
       "     'gate_proj',\n",
       "     'up_proj',\n",
       "     'down_proj',\n",
       "     'lm_head'],\n",
       "    'bias': 'none',\n",
       "    'lora_dropout': 0.05}},\n",
       "  'run_history': [{'loss': 39.6712,\n",
       "    'grad_norm': 10.52716064453125,\n",
       "    'learning_rate': 0.0,\n",
       "    'epoch': 0.46029919447640966,\n",
       "    'step': 100},\n",
       "   {'train_runtime': 49.3193,\n",
       "    'train_samples_per_second': 16.221,\n",
       "    'train_steps_per_second': 2.028,\n",
       "    'total_flos': 106525124198400.0,\n",
       "    'train_loss': 39.67122802734375,\n",
       "    'epoch': 0.46029919447640966,\n",
       "    'step': 100}]}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rungpu import Status\n",
    "st_obj = Status(run_id)\n",
    "status = st_obj.get_status()\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: text. If text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 1,738\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 100\n",
      "  Number of trainable parameters = 816,416\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-10\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-20\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-30\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-40\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-50\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-60\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-70\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-80\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-90\n",
      "Saving model checkpoint to /home/rungpu/models//distilbert-distilgpt2/8-bit/distilbert-distilgpt2-8-bit-7bf888be-2475-11ef-9ec8-b8ca3a5c98fc-rungpu_dataset_ba33febd-47a2-4b3d-b818-f0ec64610d7c/checkpoint-100\n",
      "Training Completed.\n"
     ]
    }
   ],
   "source": [
    "st_obj.progress()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's check if our finetuned model has made it to the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'RUNNING', 'message': 'Your job is still running, try again later'}\n"
     ]
    }
   ],
   "source": [
    "signed_url = finetune.get_model(run_id)\n",
    "signed_url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
